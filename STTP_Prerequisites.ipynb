{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Program: Using DataLoader in PyTorch"
      ],
      "metadata": {
        "id": "lXAhyUvL9Yg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "# Step 1: Create a custom dataset\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data, targets):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data (list): List of input data.\n",
        "            targets (list): List of corresponding labels/targets.\n",
        "        \"\"\"\n",
        "        self.data = data\n",
        "        self.targets = targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Returns a single sample and its corresponding target.\n",
        "        \"\"\"\n",
        "        sample = self.data[idx]\n",
        "        target = self.targets[idx]\n",
        "        return sample, target\n",
        "\n",
        "# Step 2: Create dummy data\n",
        "data = torch.tensor([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0], [7.0, 8.0]])\n",
        "targets = torch.tensor([0, 1, 0, 1])\n",
        "# Step 3: Create a dataset instance\n",
        "dataset = CustomDataset(data, targets)\n",
        "# Step 4: Create a DataLoader\n",
        "dataloader = DataLoader(\n",
        "    dataset,          # Dataset to load\n",
        "    batch_size=2,     # Number of samples per batch\n",
        "    shuffle=True,     # Shuffle the data\n",
        "    num_workers=0     # Number of subprocesses for data loading (0 means no parallel loading)\n",
        ")\n",
        "# Step 5: Iterate over the DataLoader\n",
        "for batch_idx, (batch_data, batch_targets) in enumerate(dataloader):\n",
        "    print(f\"Batch {batch_idx + 1}:\")\n",
        "    print(f\"Data: {batch_data}\")\n",
        "    print(f\"Targets: {batch_targets}\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQW4pbqP8uRF",
        "outputId": "d8c3e068-6116-4dab-f06c-779315dd58d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1:\n",
            "Data: tensor([[1., 2.],\n",
            "        [5., 6.]])\n",
            "Targets: tensor([0, 0])\n",
            "\n",
            "Batch 2:\n",
            "Data: tensor([[7., 8.],\n",
            "        [3., 4.]])\n",
            "Targets: tensor([1, 1])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolution and Deconvloution Operation in Pytorch"
      ],
      "metadata": {
        "id": "7A1RDrFR9gMB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7nt_Rw55EBB",
        "outputId": "ccdee0f7-00cb-4702-9353-6f39647b6283"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 5, 5])\n",
            "Convolution Output:\n",
            "tensor([[[[ -8.3397,  -9.5277, -10.7158],\n",
            "          [-14.2798, -15.4679, -16.6559],\n",
            "          [-20.2200, -21.4080, -22.5960]]]], grad_fn=<ConvolutionBackward0>)\n",
            "\n",
            "Deconvolution Output:\n",
            "tensor([[[[ -2.7461,  -0.7061,  -1.3982,   2.2068,  -0.9870],\n",
            "          [ -6.5580,  -2.4381,  -2.9141,   5.2747,  -0.3346],\n",
            "          [-10.4297,  -4.8683,  -6.4579,   5.5333,  -1.5770],\n",
            "          [ -5.9299,  -5.8474,  -5.9485,   0.5498,   0.0721],\n",
            "          [ -1.6406,  -3.2902,  -6.0997,  -4.6626,  -3.0725]]]],\n",
            "       grad_fn=<ConvolutionBackward0>)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define input (batch size = 1, channels = 1, height = 5, width = 5)\n",
        "input = torch.tensor([[\n",
        "    [1, 2, 3, 4, 5],\n",
        "    [6, 7, 8, 9, 10],\n",
        "    [11, 12, 13, 14, 15],\n",
        "    [16, 17, 18, 19, 20],\n",
        "    [21, 22, 23, 24, 25]\n",
        "]], dtype=torch.float32).unsqueeze(0)  # Add batch and channel dimensions\n",
        "print(input.shape)\n",
        "\n",
        "# Define a convolution layer\n",
        "conv_layer = nn.Conv2d(\n",
        "    in_channels=1,       # Input channels\n",
        "    out_channels=1,      # Output channels\n",
        "    kernel_size=3,       # Kernel size (3x3)\n",
        "    stride=1,            # Stride\n",
        "    padding=0            # No padding\n",
        ")\n",
        "\n",
        "# Define a deconvolution (transposed convolution) layer\n",
        "deconv_layer = nn.ConvTranspose2d(\n",
        "    in_channels=1,       # Input channels\n",
        "    out_channels=1,      # Output channels\n",
        "    kernel_size=3,       # Kernel size (3x3)\n",
        "    stride=1,            # Stride\n",
        "    padding=0            # No padding\n",
        ")\n",
        "\n",
        "# Perform convolution\n",
        "output_conv = conv_layer(input)\n",
        "print(\"Convolution Output:\")\n",
        "print(output_conv)\n",
        "\n",
        "# Perform deconvolution\n",
        "output_deconv = deconv_layer(output_conv)\n",
        "print(\"\\nDeconvolution Output:\")\n",
        "print(output_deconv)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sequential Convolution Block Example"
      ],
      "metadata": {
        "id": "5aG4rtWrW9dU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "# Define a convolutional block using nn.Sequential\n",
        "conv_block = nn.Sequential(\n",
        "    # Convolutional layer\n",
        "    nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
        "    # Batch normalization layer\n",
        "    nn.BatchNorm2d(64),\n",
        "    # ReLU activation function\n",
        "    nn.ReLU(inplace=True)\n",
        ")\n",
        "# Print the convolutional block\n",
        "print(conv_block)\n",
        "# Example input tensor (batch_size, channels, height, width)\n",
        "input_tensor = torch.randn(1, 3, 32, 32)\n",
        "# Forward pass through the convolutional block\n",
        "output_tensor = conv_block(input_tensor)\n",
        "# Print the shape of the output tensor\n",
        "print(output_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kQhpcXbW6KM",
        "outputId": "550424b2-a62a-4e7f-b0e7-2f9ad8039515"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU(inplace=True)\n",
            ")\n",
            "torch.Size([1, 64, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MSE Loss function\n"
      ],
      "metadata": {
        "id": "u1Kmeoj_V6Ia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#nn.MSELoss() Example (Regression)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "# Define a simple linear regression model\n",
        "class LinearRegression(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LinearRegression, self).__init__()\n",
        "        self.linear = nn.Linear(1, 1)  # 1 input feature, 1 output\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "# Create model, loss function, and optimizer\n",
        "model = LinearRegression()\n",
        "criterion = nn.MSELoss()  # Mean Squared Error Loss\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "# Dummy data (y = 2x + 1)\n",
        "x = torch.tensor([[1.0], [2.0], [3.0], [4.0]])\n",
        "y = torch.tensor([[3.0], [5.0], [7.0], [9.0]])\n",
        "# Training loop\n",
        "for epoch in range(100):\n",
        "    # Forward pass\n",
        "    predictions = model(x)\n",
        "    loss = criterion(predictions, y)\n",
        "    # Backward pass and optimization\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/100], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Test the model\n",
        "test_x = torch.tensor([[5.0]])\n",
        "predicted_y = model(test_x)\n",
        "print(f'Prediction for input {test_x.item()}: {predicted_y.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VxRocdf5LLd",
        "outputId": "74027f12-59e1-4bf8-86bc-bd76043cb088"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 1.8676\n",
            "Epoch [20/100], Loss: 0.0709\n",
            "Epoch [30/100], Loss: 0.0231\n",
            "Epoch [40/100], Loss: 0.0207\n",
            "Epoch [50/100], Loss: 0.0194\n",
            "Epoch [60/100], Loss: 0.0183\n",
            "Epoch [70/100], Loss: 0.0172\n",
            "Epoch [80/100], Loss: 0.0162\n",
            "Epoch [90/100], Loss: 0.0153\n",
            "Epoch [100/100], Loss: 0.0144\n",
            "Prediction for input 5.0: 10.7950\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Binary Cross Entropy Loss function\n"
      ],
      "metadata": {
        "id": "j13KbB669rzd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define a simple binary classification model\n",
        "class BinaryClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BinaryClassifier, self).__init__()\n",
        "        self.linear = nn.Linear(1, 1)  # 1 input feature, 1 output\n",
        "        self.sigmoid = nn.Sigmoid()    # Sigmoid activation for binary classification\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.sigmoid(self.linear(x))\n",
        "\n",
        "# Create model, loss function, and optimizer\n",
        "model = BinaryClassifier()\n",
        "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "# Dummy data (y = 0 for x < 2.5, y = 1 for x >= 2.5)\n",
        "x = torch.tensor([[1.0], [2.0], [3.0], [4.0]])\n",
        "y = torch.tensor([[0.0], [0.0], [1.0], [1.0]])\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(100):\n",
        "    # Forward pass\n",
        "    predictions = model(x)\n",
        "    loss = criterion(predictions, y)\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/100], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Test the model\n",
        "test_x = torch.tensor([[2.0], [3.0]])\n",
        "predicted_y = model(test_x)\n",
        "print(f'Predictions for input {test_x.squeeze().tolist()}: {predicted_y.squeeze().tolist()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ap_2OEil7YIK",
        "outputId": "a54db72a-e4ff-442c-ff9b-a5b306907685"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 0.5992\n",
            "Epoch [20/100], Loss: 0.5495\n",
            "Epoch [30/100], Loss: 0.5291\n",
            "Epoch [40/100], Loss: 0.5109\n",
            "Epoch [50/100], Loss: 0.4940\n",
            "Epoch [60/100], Loss: 0.4781\n",
            "Epoch [70/100], Loss: 0.4633\n",
            "Epoch [80/100], Loss: 0.4494\n",
            "Epoch [90/100], Loss: 0.4364\n",
            "Epoch [100/100], Loss: 0.4242\n",
            "Predictions for input [2.0, 3.0]: [0.5258750915527344, 0.7042549848556519]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u7FJLkYT7yL0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}