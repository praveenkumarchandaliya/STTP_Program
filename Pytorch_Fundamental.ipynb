{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORqoNRLK1oyjnfAOCZQcad",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/praveenkumarchandaliya/STTP_Program/blob/AEProgram/Pytorch_Fundamental.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch Fundamentals: Your First Steps into Hands-on Deep Learning\n",
        "\n",
        "This notebook provides an introduction to PyTorch, covering tensor initialization, operations, indexing, and reshaping.\n",
        "Follow along to learn the basics with clear examples and detailed explanations.\n",
        "# Table of Contents\n",
        "\n",
        "- [What are Tensors?](#What-are-Tensors?)\n",
        "- [Tensor Initialization](#Tensor-Initialization)\n",
        "- [Common Tensor Initialization Methods](#Common-Tensor-Initialization-Methods)\n",
        "- [Tensor Type Conversion](#Tensor-Type-Conversion)\n",
        "- [Converting Between NumPy Arrays and Tensors](#Converting-Between-NumPy-Arrays-and-Tensors)\n",
        "- [Tensor Mathematics and Comparison Operations](#Tensor-Mathematics-and-Comparison-Operations)\n",
        "- [Matrix Multiplication and Batch Operations](#Matrix-Multiplication-and-Batch-Operations)\n",
        "- [Broadcasting and Other Useful Operations](#Broadcasting-and-Other-Useful-Operations)\n",
        "- [Tensor Indexing](#Tensor-Indexing)\n",
        "- [Tensor Reshaping](#Tensor-Reshaping)"
      ],
      "metadata": {
        "id": "xkcCV_75J0_u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86qeEXWqFzP3",
        "outputId": "34f6c6c4-658e-497a-fe86-0aae6456eb2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch version: 2.6.0+cu124\n",
            "numpy version: 2.0.2\n",
            "python version:  3.11.12 (main, Apr  9 2025, 08:55:54) [GCC 11.4.0]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import sys # Import the sys module\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# Print versions\n",
        "print(\"torch version:\", torch.__version__)\n",
        "print(\"numpy version:\", np.__version__)\n",
        "print(\"python version: \",sys.version)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What are Tensors?\n",
        "\n",
        "Tensor holds a multi-dimensional array of elements of a single data type which is very similar with numpyâ€™s ndarray. When the dimension is zero, it can be called a scalar. When the dimension is 1, it can be called a vector. When the dimension is 2, it can be called a matrix.\n",
        "\n",
        "- 0-dimensional tensor: A single number (scalar).\n",
        "- 1-dimensional tensor: A list of numbers (vector).\n",
        "- 2-dimensional tensor: A table of numbers (matrix).\n",
        "\n",
        "When the dimension is greater than 2, it is usually called a tensor.\n",
        "\n",
        "<img src=\"data:image/webp;base64,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\" alt=\"Logo\" style=\"width:800px;\">"
      ],
      "metadata": {
        "id": "gF1rjcN7Ks4U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor Initialization\n",
        "\n",
        "This code creates a 2Ã—3 PyTorch tensor with float32 data type, assigns it to a specified device (CPU or GPU), and enables gradient tracking for backpropagation."
      ],
      "metadata": {
        "id": "tExf7zfpLeQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for CUDA availability and set the device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Initialize a 2x3 tensor with requires_grad enabled\n",
        "my_tensor = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float32, device=device, requires_grad=True)\n",
        "\n",
        "print(my_tensor)\n",
        "print(\"Data type:\", my_tensor.dtype)\n",
        "print(\"Device:\", my_tensor.device)\n",
        "print(\"Shape:\", my_tensor.shape)\n",
        "print(\"Requires Gradient:\", my_tensor.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Dq8XEh9LtEF",
        "outputId": "226611eb-d842-4711-c6cc-c89cc12d05ac"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]], requires_grad=True)\n",
            "Data type: torch.float32\n",
            "Device: cpu\n",
            "Shape: torch.Size([2, 3])\n",
            "Requires Gradient: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Other Common Tensor Initialization Methods\n",
        "\n",
        "- **Empty Tensor:** Creates an uninitialized 3Ã—3 tensor (random values).\n",
        "- **Zeros Tensor:** Creates a 3Ã—3 tensor filled with zeros.\n",
        "- **Random Tensor:** Generates a 3Ã—3 tensor with random values between 0 and 1.\n",
        "- **Ones Tensor:** Creates a 3Ã—3 tensor filled with ones.\n",
        "- **Identity Matrix:** Generates a 4Ã—4 identity matrix (diagonal of ones).\n",
        "- **Arange Tensor:** Creates a 1D tensor with values from 0 to 4 (step of 1).\n",
        "- **Linspace Tensor:** Generates 5 evenly spaced values between 0.1 and 1.\n",
        "- **Normal Distributed Tensor:** Fills a tensor with values from a normal (Gaussian) distribution with mean 0 and std 1.\n",
        "- **Uniform Distributed Tensor:** Fills a tensor with values from a uniform distribution between 0 and 1.\n",
        "- **Diagonal Tensor:** Creates a 4Ã—4 diagonal tensor with ones along the diagonal and zeros elsewhere."
      ],
      "metadata": {
        "id": "f1B52N8oMFMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an empty tensor of size 3x3\n",
        "x = torch.empty(3, 3)\n",
        "print(\"Empty Tensor:\\n\", x)\n",
        "\n",
        "# Create a tensor filled with zeros\n",
        "x = torch.zeros(3, 3)\n",
        "print(\"Zeros Tensor:\\n\", x)\n",
        "\n",
        "# Create a tensor with random values\n",
        "x = torch.rand(3, 3)\n",
        "print(\"Random Tensor:\\n\", x)\n",
        "\n",
        "# Create a tensor filled with ones\n",
        "x = torch.ones(3, 3)\n",
        "print(\"Ones Tensor:\\n\", x)\n",
        "\n",
        "# Create an identity matrix\n",
        "x = torch.eye(4, 4)\n",
        "print(\"Identity Matrix:\\n\", x)\n",
        "\n",
        "# Create a tensor using arange\n",
        "x = torch.arange(5)\n",
        "print(\"Arange Tensor:\\n\", x)\n",
        "\n",
        "# Create a tensor using linspace\n",
        "x = torch.linspace(0.1, 1, 5)\n",
        "print(\"Linspace Tensor:\\n\", x)\n",
        "\n",
        "# Create a tensor with values drawn from a normal distribution\n",
        "x = torch.empty(1, 5).normal_(mean=0, std=1)\n",
        "print(\"Normal Distributed Tensor:\\n\", x)\n",
        "\n",
        "# Create a tensor with values drawn from a uniform distribution\n",
        "x = torch.empty(1, 5).uniform_(0, 1)\n",
        "print(\"Uniform Distributed Tensor:\\n\", x)\n",
        "\n",
        "# Create a diagonal tensor from a tensor of ones\n",
        "x = torch.diag(torch.ones(4))\n",
        "print(\"Diagonal Tensor:\\n\", x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvro9QZjLtju",
        "outputId": "95bf4218-80e0-4e79-f115-fe72c069af00"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty Tensor:\n",
            " tensor([[4.6690e-01, 4.4771e-41, 4.6690e-01],\n",
            "        [4.4771e-41, 0.0000e+00, 2.1250e+00],\n",
            "        [0.0000e+00, 2.2500e+00, 0.0000e+00]])\n",
            "Zeros Tensor:\n",
            " tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "Random Tensor:\n",
            " tensor([[0.9976, 0.1536, 0.0155],\n",
            "        [0.9138, 0.1131, 0.2660],\n",
            "        [0.7795, 0.4582, 0.0969]])\n",
            "Ones Tensor:\n",
            " tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "Identity Matrix:\n",
            " tensor([[1., 0., 0., 0.],\n",
            "        [0., 1., 0., 0.],\n",
            "        [0., 0., 1., 0.],\n",
            "        [0., 0., 0., 1.]])\n",
            "Arange Tensor:\n",
            " tensor([0, 1, 2, 3, 4])\n",
            "Linspace Tensor:\n",
            " tensor([0.1000, 0.3250, 0.5500, 0.7750, 1.0000])\n",
            "Normal Distributed Tensor:\n",
            " tensor([[-0.0785,  1.3974,  0.7326, -0.5687,  0.5412]])\n",
            "Uniform Distributed Tensor:\n",
            " tensor([[0.4338, 0.5414, 0.0036, 0.4291, 0.4738]])\n",
            "Diagonal Tensor:\n",
            " tensor([[1., 0., 0., 0.],\n",
            "        [0., 1., 0., 0.],\n",
            "        [0., 0., 1., 0.],\n",
            "        [0., 0., 0., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor Type Conversion\n",
        "\n",
        "Creates a tensor with values [0, 1, 2, 3] and demonstrates type conversion to boolean, int16, int64, float16, float32, and float64."
      ],
      "metadata": {
        "id": "4Z_Ts_wPM6pb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor and convert its type\n",
        "tensor = torch.arange(4)\n",
        "print(\"Boolean Tensor:\", tensor.bool())   # Convert to boolean\n",
        "print(\"Short Tensor (int16):\", tensor.short())   # Convert to int16\n",
        "print(\"Long Tensor (int64):\", tensor.long())   # Convert to int64\n",
        "print(\"Half Tensor (float16):\", tensor.half())   # Convert to float16\n",
        "print(\"Float Tensor (float32):\", tensor.float())   # Convert to float32\n",
        "print(\"Double Tensor (float64):\", tensor.double())   # Convert to float64"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaEVKBFJMaV4",
        "outputId": "2e406866-3664-4f01-d598-45cdf43e3c07"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Boolean Tensor: tensor([False,  True,  True,  True])\n",
            "Short Tensor (int16): tensor([0, 1, 2, 3], dtype=torch.int16)\n",
            "Long Tensor (int64): tensor([0, 1, 2, 3])\n",
            "Half Tensor (float16): tensor([0., 1., 2., 3.], dtype=torch.float16)\n",
            "Float Tensor (float32): tensor([0., 1., 2., 3.])\n",
            "Double Tensor (float64): tensor([0., 1., 2., 3.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converting Between NumPy Arrays and Tensors\n",
        "\n",
        "PyTorch makes it easy to switch between NumPy arrays and tensors, allowing seamless integration with existing computing workflows."
      ],
      "metadata": {
        "id": "Dxeqo7bQNgZd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a NumPy array of zeros\n",
        "np_array = np.zeros((5, 5))\n",
        "print(\"NumPy Array:\\n\", np_array)\n",
        "# Convert NumPy array to PyTorch tensor\n",
        "tensor = torch.from_numpy(np_array)\n",
        "print(\"Tensor from NumPy Array:\\n\", tensor)\n",
        "# Convert tensor back to NumPy array\n",
        "numpy_back = tensor.numpy()\n",
        "print(\"Converted Back to NumPy Array:\\n\", numpy_back)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCRHx3JFNhM7",
        "outputId": "8271184e-f925-41ef-ebf4-6e68aef09303"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy Array:\n",
            " [[0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]]\n",
            "Tensor from NumPy Array:\n",
            " tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "Converted Back to NumPy Array:\n",
            " [[0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor Mathematics and Comparison Operations\n",
        "\n",
        "This section explores essential math operations with PyTorch tensors.\n",
        "\n",
        "- **Addition & Subtraction:** Adds and subtracts two tensors element-wise.  \n",
        "- **Division:** Uses true division for precise results.  \n",
        "- **Inplace Operations:** Modifies a tensor directly without creating a new one.  \n",
        "- **Exponentiation:** Raises each element to a power using `pow()` or `**`.  \n",
        "- **Comparisons:** Checks conditions like `x > 0` or `x < 0`, returning boolean results.  \n",
        "- **Dot Product:** Computes the sum of element-wise multiplications between two tensors."
      ],
      "metadata": {
        "id": "a-PFkjurOMKk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define two tensors for operations\n",
        "x = torch.tensor([1, 2, 3])\n",
        "y = torch.tensor([9, 8, 7])\n",
        "\n",
        "# Addition\n",
        "z = x + y\n",
        "print(\"Addition Results:\", z)\n",
        "\n",
        "# Addition using .add\n",
        "z1 = torch.empty(3)\n",
        "torch.add(x, y, out=z1)\n",
        "z2 = torch.add(x, y)\n",
        "print(\"Addition Results:\", z, z1, z2)\n",
        "\n",
        "# Subtraction\n",
        "z = x - y\n",
        "print(\"Subtraction Result:\", z)\n",
        "\n",
        "# Division (true division)\n",
        "z = torch.true_divide(x, y)\n",
        "print(\"Division Result:\", z)\n",
        "\n",
        "# Inplace operations\n",
        "t = torch.ones(3)\n",
        "print(\"Before inplace addition:\", t)\n",
        "t.add_(x)\n",
        "print(\"After inplace addition:\", t)\n",
        "t += x  # Another inplace addition (note: t = t + x creates a new tensor)\n",
        "print(\"After second inplace addition:\", t)\n",
        "\n",
        "# Exponentiation\n",
        "z = x.pow(2)\n",
        "print(\"Exponentiation (pow):\", z)\n",
        "z = x**2\n",
        "print(\"Exponentiation (**):\", z)\n",
        "\n",
        "# Comparisons\n",
        "z = x > 0\n",
        "print(\"x > 0:\", z)\n",
        "z = x < 0\n",
        "print(\"x < 0:\", z)\n",
        "\n",
        "# Dot product\n",
        "z = torch.dot(x, y)\n",
        "print(\"Dot Product:\", z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRm5eiwKNpUI",
        "outputId": "cdd04750-2409-499d-b267-4f5978598e8c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Addition Results: tensor([10, 10, 10])\n",
            "Addition Results: tensor([10, 10, 10]) tensor([10., 10., 10.]) tensor([10, 10, 10])\n",
            "Subtraction Result: tensor([-8, -6, -4])\n",
            "Division Result: tensor([0.1111, 0.2500, 0.4286])\n",
            "Before inplace addition: tensor([1., 1., 1.])\n",
            "After inplace addition: tensor([2., 3., 4.])\n",
            "After second inplace addition: tensor([3., 5., 7.])\n",
            "Exponentiation (pow): tensor([1, 4, 9])\n",
            "Exponentiation (**): tensor([1, 4, 9])\n",
            "x > 0: tensor([True, True, True])\n",
            "x < 0: tensor([False, False, False])\n",
            "Dot Product: tensor(46)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Matrix Multiplication and Batch Operations\n",
        "\n",
        "Matrix operations are at the heart of deep learning. Let's find out different ways to perform multiplication.\n",
        "\n",
        "- **Matrix Multiplication:** Uses `@` or `torch.mm()` to perform standard matrix multiplication.  \n",
        "- **Matrix Exponentiation:** Raises a square matrix to a power using `matrix_power(n)`.  \n",
        "- **Element-wise Multiplication:** Uses `torch.mul()` or `*` for element-wise multiplication.  \n",
        "- **Batch Matrix Multiplication:** Uses `torch.bmm()` to multiply batches of matrices efficiently."
      ],
      "metadata": {
        "id": "r78UuqCSQD2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix multiplication using @ operator and torch.mm\n",
        "x2 = torch.tensor([[1, 2, 3]])\n",
        "y2 = torch.tensor([[9, 8, 7]])\n",
        "\n",
        "z = x2 @ torch.t(y2)\n",
        "print(\"Matrix Multiplication (@ operator):\\n\", z)\n",
        "z = torch.mm(x2, torch.t(y2))\n",
        "print(\"Matrix Multiplication (torch.mm):\\n\", z)\n",
        "z = x2.mm(torch.t(y2))\n",
        "print(\"Matrix Multiplication (mm):\\n\", z)\n",
        "\n",
        "# Matrix exponentiation: multiplying a matrix with itself 3 times\n",
        "matrix_exp = torch.rand(5, 5)\n",
        "print(\"Matrix multiplied 3 times:\\n\", matrix_exp @ matrix_exp @ matrix_exp)\n",
        "print(\"Matrix power 3:\\n\", matrix_exp.matrix_power(3))\n",
        "\n",
        "# Element-wise multiplication\n",
        "z = torch.mul(x, y)\n",
        "print(\"Element-wise Multiplication:\", z)\n",
        "z = x * y\n",
        "print(\"Element-wise Multiplication (alternative):\", z)\n",
        "\n",
        "# Batch matrix multiplication\n",
        "batch = 32\n",
        "n, m, p = 10, 20, 30\n",
        "tensor1 = torch.rand((batch, n, m))\n",
        "tensor2 = torch.rand((batch, m, p))\n",
        "out_bmm = torch.bmm(tensor1, tensor2)  # Result shape: (batch, n, p)\n",
        "print(\"Batch Matrix Multiplication (first batch):\\n\", out_bmm[0])\n",
        "print(\"Shape of batched multiplication result:\", (tensor1 @ tensor2).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCJXVVa5OqtZ",
        "outputId": "31fdb300-0446-477f-dfed-69dcbce9140d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix Multiplication (@ operator):\n",
            " tensor([[46]])\n",
            "Matrix Multiplication (torch.mm):\n",
            " tensor([[46]])\n",
            "Matrix Multiplication (mm):\n",
            " tensor([[46]])\n",
            "Matrix multiplied 3 times:\n",
            " tensor([[3.2862, 3.4477, 2.8051, 4.4104, 3.6545],\n",
            "        [3.6619, 3.9597, 3.2059, 4.9938, 3.9905],\n",
            "        [5.2525, 5.7016, 4.5615, 7.2101, 5.7575],\n",
            "        [5.7636, 5.9299, 4.9231, 7.6378, 6.3206],\n",
            "        [4.1122, 4.5994, 3.6926, 5.7100, 4.5616]])\n",
            "Matrix power 3:\n",
            " tensor([[3.2862, 3.4477, 2.8051, 4.4104, 3.6545],\n",
            "        [3.6619, 3.9597, 3.2059, 4.9938, 3.9905],\n",
            "        [5.2525, 5.7016, 4.5615, 7.2101, 5.7575],\n",
            "        [5.7636, 5.9299, 4.9231, 7.6378, 6.3206],\n",
            "        [4.1122, 4.5994, 3.6926, 5.7100, 4.5616]])\n",
            "Element-wise Multiplication: tensor([ 9, 16, 21])\n",
            "Element-wise Multiplication (alternative): tensor([ 9, 16, 21])\n",
            "Batch Matrix Multiplication (first batch):\n",
            " tensor([[5.8679, 5.3618, 6.4725, 5.8707, 5.8277, 6.1958, 8.2317, 4.8718, 7.9212,\n",
            "         8.0798, 8.5718, 7.5948, 6.2685, 6.8662, 7.0205, 6.5277, 6.4879, 7.2025,\n",
            "         5.9125, 6.3886, 5.8646, 5.4287, 8.4203, 8.1030, 7.2122, 7.6047, 6.5145,\n",
            "         7.8953, 7.5716, 6.8193],\n",
            "        [4.2114, 4.3618, 4.2111, 4.4123, 3.6423, 3.6392, 5.7717, 3.2150, 5.5025,\n",
            "         5.8034, 6.1516, 5.3958, 5.0861, 4.7371, 4.8330, 5.1945, 4.4308, 4.9172,\n",
            "         4.6628, 4.6649, 4.2636, 3.5661, 6.1783, 5.3763, 5.4017, 5.1939, 3.8794,\n",
            "         5.5483, 4.9229, 4.7678],\n",
            "        [4.8236, 4.9100, 5.7601, 5.4490, 4.9671, 5.3451, 6.9925, 4.4212, 6.4427,\n",
            "         7.0810, 6.7609, 6.1679, 5.6549, 6.0413, 5.4189, 5.0882, 5.4462, 6.0564,\n",
            "         5.1906, 4.8703, 5.1451, 4.9197, 6.9861, 6.3400, 6.0953, 6.5522, 6.0646,\n",
            "         5.9562, 6.2804, 6.1660],\n",
            "        [5.2781, 5.0261, 5.1839, 5.3795, 5.0549, 5.1740, 7.0331, 4.2424, 6.7185,\n",
            "         7.5526, 6.9140, 6.1530, 5.2925, 6.0346, 5.2620, 5.8613, 4.9850, 6.1808,\n",
            "         5.2424, 5.6098, 5.3274, 4.6201, 7.0566, 7.0282, 6.4594, 6.3009, 6.1666,\n",
            "         6.2855, 6.3467, 5.9794],\n",
            "        [5.3223, 4.9331, 5.1862, 5.9077, 5.1150, 4.9066, 6.4829, 4.2071, 6.7060,\n",
            "         7.2901, 6.6178, 6.5088, 5.0533, 5.8025, 5.2366, 5.5547, 4.9859, 5.7142,\n",
            "         5.3607, 4.9150, 5.4818, 3.8685, 6.8348, 7.0872, 5.9336, 6.1000, 5.7805,\n",
            "         6.3106, 6.4026, 5.6670],\n",
            "        [3.7567, 4.0917, 4.5120, 4.4514, 4.4277, 3.9483, 5.9424, 4.2745, 5.1483,\n",
            "         5.1159, 5.2881, 5.0120, 3.8932, 5.0527, 4.4259, 4.7620, 4.2987, 5.0448,\n",
            "         3.6121, 4.5617, 3.5978, 4.1047, 5.5394, 4.9703, 4.5111, 4.8173, 4.2619,\n",
            "         4.4644, 4.8650, 4.9593],\n",
            "        [4.6867, 4.2755, 5.7808, 5.6872, 4.6788, 5.3316, 6.5705, 4.5933, 6.4718,\n",
            "         6.4484, 6.4792, 6.3582, 5.2295, 5.5712, 5.3344, 4.9736, 4.9591, 5.4972,\n",
            "         4.6719, 4.3891, 5.0161, 4.3706, 6.7872, 6.1909, 5.4854, 6.3240, 5.7178,\n",
            "         6.1700, 6.2036, 5.7258],\n",
            "        [4.8396, 4.2096, 5.0414, 4.9197, 4.4774, 4.0738, 5.0600, 3.7980, 5.1976,\n",
            "         5.8436, 5.9628, 4.5947, 4.4955, 5.0597, 4.5720, 4.6701, 4.8529, 4.6023,\n",
            "         4.2583, 3.8100, 4.9836, 3.6133, 5.7977, 4.9780, 4.2892, 5.2036, 5.1212,\n",
            "         4.4470, 6.1600, 4.6720],\n",
            "        [4.8586, 4.5071, 5.4594, 5.5360, 4.9835, 5.0726, 6.4087, 4.6408, 5.8912,\n",
            "         6.4221, 6.2243, 5.2579, 5.6857, 5.7776, 5.2305, 4.5486, 4.4668, 5.0314,\n",
            "         4.6130, 3.9264, 4.9956, 4.3159, 6.2282, 6.0233, 4.9102, 5.9227, 5.0300,\n",
            "         5.4781, 6.2919, 5.3024],\n",
            "        [3.8124, 4.2034, 4.2034, 3.8471, 4.1745, 3.6963, 4.4661, 3.1771, 4.7615,\n",
            "         4.9697, 5.9370, 4.6470, 3.5191, 4.6645, 4.3020, 4.5668, 4.4541, 4.5154,\n",
            "         3.6961, 4.7577, 3.8663, 2.9673, 5.0726, 5.0622, 4.6679, 4.3966, 3.6288,\n",
            "         4.3239, 4.6159, 4.2453]])\n",
            "Shape of batched multiplication result: torch.Size([32, 10, 30])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Broadcasting and Other Useful Operations\n",
        "\n",
        "Broadcasting allows arithmetic operations on tensors of different shapes. This section also demonstrates additional useful functions.\n",
        "\n",
        "- **Broadcasting:** Automatically expands smaller tensors to match larger ones in operations.  \n",
        "- **Summation:** `torch.sum(x, dim=0)` computes sum along a specific dimension.  \n",
        "- **Min/Max Values:** `torch.max()` and `torch.min()` return the highest and lowest values along a dimension.  \n",
        "- **Absolute Values:** `torch.abs(x)` gets the element-wise absolute values.  \n",
        "- **Argmax/Argmin:** `torch.argmax()` and `torch.argmin()` return the index of max/min values.  \n",
        "- **Mean Calculation:** `torch.mean(x.float(), dim=0)` computes the mean (ensuring float dtype).  \n",
        "- **Element-wise Comparison:** `torch.eq(x, y)` checks equality between two tensors.  \n",
        "- **Sorting:** `torch.sort(y, dim=0)` sorts tensor elements and returns indices.  \n",
        "- **Clamping:** `torch.clamp(x, min=0)` restricts values within a range.  \n",
        "- **Boolean Operations:** `torch.any(x_bool)` checks if any value is `True`, `torch.all(x_bool)` checks if all are `True`."
      ],
      "metadata": {
        "id": "gRqp4o03RF0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Broadcasting example\n",
        "x1 = torch.rand(5, 5)\n",
        "x2 = torch.rand(5)\n",
        "print(\"Tensor x1:\\n\", x1)\n",
        "print(\"Tensor x2:\\n\", x2)\n",
        "print(\"x1 - x2:\\n\", x1 - x2)\n",
        "print(\"x1 raised to the power of x2:\\n\", x1 ** x2)\n",
        "\n",
        "# Sum of tensor elements along dimension 0\n",
        "sum_x = torch.sum(x, dim=0)\n",
        "print(\"Sum along dimension 0:\", sum_x)\n",
        "\n",
        "# Maximum and minimum values\n",
        "value, indices = torch.max(x, dim=0)\n",
        "print(\"Max value and index:\", value, indices)\n",
        "\n",
        "value, indices = torch.min(x, dim=0)\n",
        "print(\"Min value and index:\", value, indices)\n",
        "\n",
        "# Other operations\n",
        "print(\"Absolute values:\", torch.abs(x))\n",
        "print(\"Argmax:\", torch.argmax(x, dim=0))\n",
        "print(\"Argmin:\", torch.argmin(x, dim=0))\n",
        "print(\"Mean (converted to float):\", torch.mean(x.float(), dim=0))\n",
        "print(\"Element-wise equality (x == y):\", torch.eq(x, y))\n",
        "\n",
        "# Sorting\n",
        "sorted_y, indices = torch.sort(y, dim=0, descending=False)\n",
        "print(\"Sorted y and indices:\", sorted_y, indices)\n",
        "\n",
        "# Clamping values\n",
        "print(\"Clamped x:\", torch.clamp(x, min=0))\n",
        "\n",
        "# Boolean operations\n",
        "x_bool = torch.tensor([1, 0, 1, 1, 1], dtype=torch.bool)\n",
        "print(\"Any True:\", torch.any(x_bool))\n",
        "print(\"All True:\", torch.all(x_bool))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjcYdAR0QXOz",
        "outputId": "7854e0b0-1234-48f6-c0c8-fbac618fed43"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor x1:\n",
            " tensor([[0.9204, 0.2059, 0.6009, 0.4407, 0.3346],\n",
            "        [0.3398, 0.8799, 0.3522, 0.2881, 0.7400],\n",
            "        [0.9038, 0.4923, 0.6685, 0.4475, 0.7791],\n",
            "        [0.0132, 0.8269, 0.9485, 0.0245, 0.9988],\n",
            "        [0.9314, 0.2159, 0.3556, 0.9932, 0.2935]])\n",
            "Tensor x2:\n",
            " tensor([0.2443, 0.8043, 0.5209, 0.9895, 0.1846])\n",
            "x1 - x2:\n",
            " tensor([[ 0.6761, -0.5983,  0.0800, -0.5488,  0.1500],\n",
            "        [ 0.0956,  0.0757, -0.1687, -0.7015,  0.5555],\n",
            "        [ 0.6596, -0.3120,  0.1475, -0.5421,  0.5945],\n",
            "        [-0.2311,  0.0226,  0.4276, -0.9650,  0.8142],\n",
            "        [ 0.6871, -0.5884, -0.1654,  0.0037,  0.1089]])\n",
            "x1 raised to the power of x2:\n",
            " tensor([[0.9799, 0.2806, 0.7670, 0.4445, 0.8170],\n",
            "        [0.7682, 0.9022, 0.5807, 0.2919, 0.9459],\n",
            "        [0.9756, 0.5655, 0.8107, 0.4513, 0.9550],\n",
            "        [0.3475, 0.8582, 0.9728, 0.0255, 0.9998],\n",
            "        [0.9828, 0.2914, 0.5835, 0.9933, 0.7975]])\n",
            "Sum along dimension 0: tensor(6)\n",
            "Max value and index: tensor(3) tensor(2)\n",
            "Min value and index: tensor(1) tensor(0)\n",
            "Absolute values: tensor([1, 2, 3])\n",
            "Argmax: tensor(2)\n",
            "Argmin: tensor(0)\n",
            "Mean (converted to float): tensor(2.)\n",
            "Element-wise equality (x == y): tensor([False, False, False])\n",
            "Sorted y and indices: tensor([7, 8, 9]) tensor([2, 1, 0])\n",
            "Clamped x: tensor([1, 2, 3])\n",
            "Any True: tensor(True)\n",
            "All True: tensor(False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor Indexing\n",
        "\n",
        "Access and modify tensor elements using indexing, slicing, and advanced indexing.\n",
        "\n",
        "- **Accessing Rows & Columns:** Use `x[row, :]` for a row and `x[:, col]` for a column.  \n",
        "- **Slicing:** `x[row, start:end]` extracts a portion of a row.  \n",
        "- **Modifying Elements:** Directly assign values using `x[row, col] = value`.  \n",
        "- **Fancy Indexing:** Use a list of indices to select multiple elements at once.  \n",
        "- **Conditional Indexing:** Extract elements using conditions like `(x < 2) | (x > 8)`.  \n",
        "- **Finding Even Numbers:** Use `x.remainder(2) == 0` to filter even values.  \n",
        "- **Conditional Selection with `torch.where()`:** Chooses values based on a condition.  "
      ],
      "metadata": {
        "id": "XT6ipME7XgKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random tensor with shape (batch_size, features)\n",
        "batch_size = 4\n",
        "features = 10\n",
        "x = torch.rand((batch_size, features))\n",
        "# Access the first row\n",
        "print(\"First row of tensor:\", x[0, :])\n",
        "# Access the second column\n",
        "print(\"Second column of tensor:\", x[:, 1])\n",
        "# Access the first 10 elements of the third row\n",
        "print(\"First 10 elements of third row:\", x[2, 0:10])\n",
        "# Modify a specific element (set first element to 100)\n",
        "x[0, 0] = 100\n",
        "# Fancy indexing example\n",
        "x1 = torch.arange(10)\n",
        "indices = [2, 5, 8]\n",
        "print(\"Fancy indexing result:\", x1[indices])\n",
        "# Advanced indexing: select elements based on a condition\n",
        "x2 = torch.arange(10)\n",
        "print(\"Elements where x2 < 2 or x2 > 8:\", x2[(x2 < 2) | (x2 > 8)])\n",
        "print(\"Even numbers in x2:\", x2[x2.remainder(2) == 0])\n",
        "# Using torch.where to select values based on a condition\n",
        "print(\"Using torch.where:\", torch.where(x2 > 5, x2, x2 * 2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFmJXDoMU3J8",
        "outputId": "2b527c23-cda3-40a2-fa69-a202680bb1df"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First row of tensor: tensor([0.2002, 0.6748, 0.2045, 0.9202, 0.4004, 0.1569, 0.6739, 0.2559, 0.1785,\n",
            "        0.1360])\n",
            "Second column of tensor: tensor([0.6748, 0.9852, 0.8801, 0.8592])\n",
            "First 10 elements of third row: tensor([0.9649, 0.8801, 0.0141, 0.5284, 0.1306, 0.2692, 0.4477, 0.2169, 0.4646,\n",
            "        0.2486])\n",
            "Fancy indexing result: tensor([2, 5, 8])\n",
            "Elements where x2 < 2 or x2 > 8: tensor([0, 1, 9])\n",
            "Even numbers in x2: tensor([0, 2, 4, 6, 8])\n",
            "Using torch.where: tensor([ 0,  2,  4,  6,  8, 10,  6,  7,  8,  9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor Reshaping\n",
        "\n",
        "Learn how to reshape tensors, concatenate them, and change the order of dimensions.\n",
        "\n",
        "- **Reshape with `view()` & `reshape()`:** Change tensor shape without altering data.  \n",
        "- **Transpose & Flatten:** `.t()` transposes, `.contiguous().view(-1)` flattens.  \n",
        "- **Concatenation:** `torch.cat([x1, x2], dim=0/1)` merges tensors along rows/columns.  \n",
        "- **Flattening:** `.view(-1)` converts a tensor into a 1D array.  \n",
        "- **Batch Reshaping:** `.view(batch, -1)` keeps batch size while reshaping.  \n",
        "- **Permute Dimensions:** `.permute(0, 2, 1)` reorders dimensions efficiently.  \n",
        "- **Unsqueeze for New Dimensions:** `.unsqueeze(dim)` adds singleton dimensions.  "
      ],
      "metadata": {
        "id": "bOGNGiLlYfw2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape a tensor using view and reshape\n",
        "x = torch.arange(9)\n",
        "x_3x3 = x.view(3, 3)\n",
        "print(\"Reshaped to 3x3 using view:\\n\", x_3x3)\n",
        "x_3x3 = x.reshape(3, 3)\n",
        "print(\"Reshaped to 3x3 using reshape:\\n\", x_3x3)\n",
        "\n",
        "# Transpose and flatten the tensor\n",
        "y = x_3x3.t()\n",
        "print(\"Flattened transposed tensor:\", y.contiguous().view(9))\n",
        "\n",
        "# Concatenation example\n",
        "x1 = torch.rand(2, 5)\n",
        "x2 = torch.rand(2, 5)\n",
        "print(\"Concatenated along dimension 0 (rows):\", torch.cat([x1, x2], dim=0).shape)\n",
        "print(\"Concatenated along dimension 1 (columns):\", torch.cat([x1, x2], dim=1).shape)\n",
        "\n",
        "# Flatten the tensor using view(-1)\n",
        "z = x1.view(-1)\n",
        "print(\"Flattened tensor shape:\", z.shape)\n",
        "\n",
        "# Reshape with batch dimension\n",
        "batch = 64\n",
        "x = torch.rand(batch, 2, 5)\n",
        "print(\"Reshaped to (batch, -1):\", x.view(batch, -1).shape)\n",
        "\n",
        "# Permute dimensions\n",
        "z = x.permute(0, 2, 1)\n",
        "print(\"Permuted tensor shape:\", z.shape)\n",
        "\n",
        "# Unsqueeze examples (adding new dimensions)\n",
        "x = torch.arange(10)\n",
        "print(\"Original x:\", x)\n",
        "print(\"x unsqueezed at dim 0:\", x.unsqueeze(0).shape, x.unsqueeze(0))\n",
        "print(\"x unsqueezed at dim 1:\", x.unsqueeze(1).shape, x.unsqueeze(1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqcOZ4oyXrIv",
        "outputId": "7667ddda-be48-41c9-d146-7e85b5ff2ab4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reshaped to 3x3 using view:\n",
            " tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [6, 7, 8]])\n",
            "Reshaped to 3x3 using reshape:\n",
            " tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [6, 7, 8]])\n",
            "Flattened transposed tensor: tensor([0, 3, 6, 1, 4, 7, 2, 5, 8])\n",
            "Concatenated along dimension 0 (rows): torch.Size([4, 5])\n",
            "Concatenated along dimension 1 (columns): torch.Size([2, 10])\n",
            "Flattened tensor shape: torch.Size([10])\n",
            "Reshaped to (batch, -1): torch.Size([64, 10])\n",
            "Permuted tensor shape: torch.Size([64, 5, 2])\n",
            "Original x: tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
            "x unsqueezed at dim 0: torch.Size([1, 10]) tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]])\n",
            "x unsqueezed at dim 1: torch.Size([10, 1]) tensor([[0],\n",
            "        [1],\n",
            "        [2],\n",
            "        [3],\n",
            "        [4],\n",
            "        [5],\n",
            "        [6],\n",
            "        [7],\n",
            "        [8],\n",
            "        [9]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0GDomZdnYjvs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}