{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.init as init\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle"
      ],
      "metadata": {
        "id": "po95i4SRWWgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHx-i0WIWcaT",
        "outputId": "75cfaab2-9c71-449c-8ec6-c3c842349349"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!unzip /content/drive/MyDrive/STTP/MRCDBlack.zip\n",
        "!cd /content/drive/MyDrive/STTP/\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLpk56V-bCfp",
        "outputId": "70c277b4-355e-41b6-d85d-74cf94537e4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aojrj2bIisUB"
      },
      "outputs": [],
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "nz = 50\n",
        "n_l = 5\n",
        "n_channel = 3\n",
        "n_disc = 16\n",
        "n_gen = 64\n",
        "nef=64\n",
        "ndf=64\n",
        "image_size=128\n",
        "#dataroot=\"/home/user_3/Downloads/Ae/MorphAging\"\n",
        "dataroot=\"/content/drive/MyDrive/STTP/FaceDataSTTP/\"\n",
        "outf=\"/content/drive/MyDrive/STTP/result\"\n",
        "manual_seed = random.randint(1, 10000)\n",
        "batch_size=64\n",
        "if use_cuda:\n",
        "    torch.cuda.manual_seed_all(manual_seed)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((image_size,image_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
        "                         std=(0.229, 0.224, 0.225))])\n",
        "datafolder = dset.ImageFolder(root=dataroot, transform=transform)\n",
        "dataloader = torch.utils.data.DataLoader(datafolder, shuffle=True, batch_size=batch_size, drop_last=True)\n",
        "nz = int(nz)\n",
        "nef = int(nef)\n",
        "ndf = int(ndf)\n",
        "nc = 3\n",
        "out_size = image_size // 16  # 64\n",
        "if use_cuda:\n",
        "    BCE = nn.BCELoss().cuda()\n",
        "    L1  = nn.L1Loss().cuda()\n",
        "    CE = nn.CrossEntropyLoss().cuda()\n",
        "    mse = nn.MSELoss().cuda()\n",
        "\n",
        "class _Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(_Encoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(nc, nef, 4, 2, padding=1),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.Conv2d(nef, nef * 2, 4, 2, padding=1),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.Conv2d(nef * 2, nef * 4, 4, 2, padding=1),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.Conv2d(nef * 4, nef * 8, 4, 2, padding=1),\n",
        "            nn.ReLU(True),\n",
        "        )\n",
        "        self.latent = nn.Linear(nef * 8 * out_size * out_size, nz)\n",
        "\n",
        "    def forward(self, input):\n",
        "        batch_size = input.size(0)\n",
        "        hidden = self.encoder(input)\n",
        "        hidden = hidden.view(batch_size, -1)\n",
        "        latent_z = self.latent(hidden)\n",
        "        return latent_z\n",
        "\n",
        "encoder = _Encoder()\n",
        "\n",
        "class _Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(_Decoder, self).__init__()\n",
        "\n",
        "        self.decoder_dense = nn.Sequential(\n",
        "            nn.Linear(nz, ndf * 8 * out_size * out_size),\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "        self.decoder_conv = nn.Sequential(\n",
        "            nn.UpsamplingNearest2d(scale_factor=2),\n",
        "            nn.Conv2d(ndf * 8, ndf * 4, 3, padding=1),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "\n",
        "            nn.UpsamplingNearest2d(scale_factor=2),\n",
        "            nn.Conv2d(ndf * 4, ndf * 2, 3, padding=1),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "\n",
        "            nn.UpsamplingNearest2d(scale_factor=2),\n",
        "            nn.Conv2d(ndf * 2, ndf, 3, padding=1),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.UpsamplingNearest2d(scale_factor=2),\n",
        "            nn.Conv2d(ndf, nc, 3, padding=1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        batch_size = z.size(0)\n",
        "        hidden = self.decoder_dense(z).view(batch_size,ndf * 8, out_size, out_size)\n",
        "        output = self.decoder_conv(hidden)\n",
        "        return output\n",
        "\n",
        "decoder = _Decoder()\n",
        "\n",
        "input = torch.FloatTensor(batch_size, nc, image_size, image_size)\n",
        "if use_cuda:\n",
        "    encoder = encoder.cuda()\n",
        "    decoder = decoder.cuda()\n",
        "    input = input.cuda()\n",
        "input = Variable(input)\n",
        "optimizerE = optim.Adam(encoder.parameters(),lr=0.0002,betas=(0.5,0.999))\n",
        "optimizerD = optim.Adam(decoder.parameters(),lr=0.0002,betas=(0.5,0.999))\n",
        "encoder.train()\n",
        "decoder.train()\n",
        "for epoch in range(10):\n",
        "    for i, (img_data, img_label) in enumerate(dataloader):\n",
        "        torch.cuda.empty_cache()\n",
        "        img_data_v = Variable(img_data)\n",
        "        if epoch == 0 and i == 0:\n",
        "            fixed_noise = img_data[:8].repeat(5, 1, 1, 1)\n",
        "            fixed_img_v = Variable(fixed_noise)\n",
        "            if use_cuda:\n",
        "                fixed_img_v = fixed_img_v.cuda()\n",
        "                #vutils.save_image(fixed_img_v.data,'{}/initial_inputs.png'.format(outf),normalize=True)\n",
        "            if use_cuda:\n",
        "               img_data_v = img_data_v.cuda()\n",
        "        batchSize = img_data_v.size(0)\n",
        "        optimizerE.zero_grad()\n",
        "        optimizerD.zero_grad()\n",
        "        input.data.copy_(img_data)\n",
        "        latent_z = encoder(input)\n",
        "        #print(\"Latent Z\",latent_z.shape)\n",
        "        recon = decoder(latent_z)\n",
        "        mse_l1  = L1(input,recon)\n",
        "        mse_l1.backward()\n",
        "        optimizerE.step()\n",
        "        optimizerD.step()\n",
        "\n",
        "        if i % 100== 0:\n",
        "           vutils.save_image(input.data,'{}/inputs.png'.format(outf),normalize=True)\n",
        "\n",
        "\n",
        "    fixed_z = encoder(fixed_img_v)\n",
        "    fixed_fake = decoder(fixed_z)\n",
        "    vutils.save_image(fixed_fake.data,'%s/reconst_epoch%03d.png' % (outf, epoch + 1),normalize=True)\n",
        "    if(i%100==0):\n",
        "      msg3 = format(\"MSE loss:%f\" % (mse_l1.item()), \"<30\")\n",
        "      print(msg3)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1XwKULCHevq8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}